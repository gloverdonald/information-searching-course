Запуск
на
Эльбрусе
платформы
для
нейросетей
PuzzleLib
/
Хабр
β
Рейтинг
Занимаемся
нейросетями
и
голосовыми
помощниками
ноя
в
:
Запуск
на
Эльбрусе
платформы
для
нейросетей
PuzzleLib
мин
K
ИИ
на
отечественном
железе
Рассказываем
о
том
как
мы
портировали
свой
фреймворк
для
нейронных
сетей
и
систему
распознавания
лиц
на
российские
процессоры
Эльбрус
Это
была
интересная
задача
весной
года
мы
рассказывали
об
этом
в
офисе
Яндекса
на
большом
митапе
про
Эльбрус
теперь
делимся
с
Хабром
Кратко
–
что
такое
Эльбрус
Это
российский
процессор
со
своей
собственной
архитектурой
разрабатываемый
в
Хорошо
о
нём
рассказывает
на
своём
канале
Максим
Горшенин:
Кратко
–
что
такое
PuzzleLib
Это
наша
платформа
для
нейронных
сетей
которую
мы
разрабатываем
и
используем
с
года
Аналог
Google
TensorFlow
и
Facebook
PyTorch
Интересно
что
PuzzleLib
поддерживает
не
только
процессоры
NVIDIA
и
Intel
но
и
видеокарты
AMD
Хотя
у
нас
небольшая
библиотека
(у
TensorFlow
порядка
млн
строк
у
нас
–
тысяч)
мы
лучше
по
скорости
–
немного
но
лучше
=)
Сейчас
мы
пока
не
в
open
source
библиотека
используется
для
наших
проектов
в
том
числе
в
проектах
нашей
сестринской
компании
по
созданию
голосовых
и
текстовых
виртуальных
ассистентов
На
PuzzleLib
производятся
все
стадии
обучения
языковых
и
акустических
моделей
и
разработка
и
адаптация
ассистентов
как
например
было
сделано
в
проектах
для
АО
«Киевстар»
(Договор
от
г
)
ООО
«UNITEL»
(Договор
от
г
)
CООО
«Мобильные
ТелеСистемы»
(Договор
от
г
)
ОАО
«Акционерный
Сберегательный
банк
«Беларусбанк»
(Договор
от
г
)
а
также
для
крупных
проектов
в
энергетической
отрасли
–
АО
«АтомЭнергоСбыт»
(Договор
от
г
)
и
АО
«ЭнергосбыТ
Плюс»
(Договор
от
г
)
Библиотека
полноценная:
поддерживает
как
стадию
обучения
(training)
так
и
стадию
вывода
(inference)
нейронных
сетей
Можно
строить
рекуррентные
свёрточные
нейросети
также
есть
интерфейс
для
создания
произвольных
графов
вычислений
В
PuzzleLib
есть
Это
привычные
знакомые
всем
кто
занимается
нейросетями
блоки
для
нейросетевых
конструкторов
(так
как
любые
фреймворки
–
это
конструкторы
состоящие
из
типовых
вычислительных
блоков
и
алгоритмов)
У
нас
возникла
идея
запустить
нашу
библиотеку
на
архитектуре
Эльбрус
Почему
мы
захотели
поддержать
Эльбрус?
Началось
все
с
того
что
мы
познакомились
с
МЦСТ
пообщались
одолжили
для
разработки
компьютер
Что
понравилось:
на
Эльбрусе
работает
Linux
в
этом
Linux
есть
python
причём
работает
он
не
в
режиме
эмуляции
–
это
полноценный
нативный
python
собранный
под
Эльбрус
Также
есть
пачка
стандартных
библиотек
python
например
numpy
которую
все
разработчики
очень
любят
Были
какие-то
задачи
под
которые
нам
приходилось
дополнительно
собирать
библиотеки:
например
в
PuzzleLib
мы
используем
формат
hdf
для
хранения
весов
нейросетей
и
соответственно
нам
пришлось
собрать
библиотеки
libhdf
и
h
py
с
помощью
компилятора
lcc
Но
никаких
проблем
сборки
у
нас
не
было
Библиотека
компьютерного
зрения
OpenCV
также
уже
была
собрана
но
к
ней
не
было
биндинга
к
python
–
его
мы
собирали
отдельно
Известная
библиотека
dlib
тоже
довольно
легко
собралась
Здесь
были
лишь
небольшие
трудности:
некоторые
файлы
этого
open
source
проекта
были
без
bom-маркера
для
определения
utf-
что
расстраивало
лексёр
lcc
Собственно
просто
был
некорректный
формат
файлов
который
пришлось
в
исходниках
поправить
Мы
решили
сначала
запустить
распознавание
лиц
Это
понятный
всем
use
case
много
где
эта
технология
используется
В
PuzzleLib
как
и
в
других
библиотеках
довольно
большая
бэкендовая
часть
то
есть
база
кода
специфичного
для
разных
процессорных
архитектур
Наши
бэкенды:
На
Эльбрусе
мы
запустили
numpy-бэкенд
что
было
очень
просто
т
к
от
платформы
требуется
минимум
всего:
Платформа
->
с
-компилятор
->
python
->
numpy
У
нас
библиотека
без
каких-либо
усложняющих
факторов
(например
без
каких-то
особенных
систем
сборки)
–
кроме
того
что
нам
необходимо
было
собрать
определённые
биндинги
Мы
запустили
тесты
всё
работает
–
и
свёрточные
сетки
и
рекуррентные
То
распознавание
лиц
которое
мы
запускали
довольно
простое
базируется
на
Inception-ResNet
Первые
результаты
работы
На
Intel
Core
i
время
обработки
одного
изображения
было
секунды
а
здесь
–
Надо
было
оптимизировать
Конечно
рассчитывать
что
numpy
будет
с
ходу
хорошо
работать
–
было
бы
неправильно
Как
мы
оптимизировали
вычисления
Мы
замерили
скорость
inference
через
профайлер
python
и
выяснили
что
почти
всё
время
тратилось
на
перемножение
матриц
в
numpy
Для
пробы
написали
самое
простое
ручное
перемножение
матрицы
и
оно
уже
оказалось
быстрее
хотя
было
непонятно
почему
Казалось
бы
numpy
dot
должен
был
быть
написан
чуть
менее
наивно
чем
такое
простое
перемножение
Тем
не
менее
мы
сбилдили
проверили
–
получилось
уже
быстрее
(
секунд
на
кадр
вместо
)
Далее
мы
узнали
о
библиотеке
линейной
алгебры
EML
которая
разрабатывается
в
МЦСТ
заменили
вызовы
np
dot
на
cblas_sgemm
Стало
в
раз
быстрее
(
секунды)
–
мы
были
очень
довольны
Далее
следовало
несколько
пошаговых
оптимизаций
Т
к
мы
запускаем
только
распознавание
лиц
а
не
в
целом
произвольные
данные
мы
решили
заточить
наши
операции
только
под
d-тензоры
и
сделать
Fusion
–
после
чего
время
обработки
снизилось
в
раза
–
до
секунд
Пояснение:
Fusion
–
это
когда
несколько
операций
объединяются
в
одну
к
примеру
свёртка
нормализация
и
активация
Вместо
того
чтобы
делать
проход
по
трём
циклам
делается
один
проход
Такие
библиотеки
есть
у
NVIDIA
()
В
неё
загружается
вычислительный
граф
а
библиотека
выдаёт
оптимизированный
ускоренный
граф
в
частности
за
счёт
того
что
она
умеет
схлопывать
операции
в
одну
Подобная
есть
и
у
Intel
(nGraph
и
)
Потом
мы
увидели
что
поскольку
было
много
свёрток
х
в
Inception-ResNet
у
нас
происходило
лишнее
копирование
данных
Мы
решили
специализироваться
под
то
что
работаем
на
батчах
из
фотографии
(то
есть
не
пачками
обрабатывать
фотографий
а
обеспечить
потоковый
режим)
–
есть
такие
use
cases
когда
нужно
работать
не
с
архивами
а
с
потоком
(например
для
видеонаблюдения
или
СКУД)
Мы
создали
специализированный
проход
без
(убрали
большие
копии)
–
стало
секунды
Потом
мы
снова
посмотрели
профайлер
у
нас
было
всё
так
же
–
хоть
все
стадии
и
сжались
по
времени
у
нас
всё
равно
%
времени
уходило
на
вычисление
свёрточных
инференс-блоков
Мы
поняли
что
нужно
параллелить
(general
matrix
multiply)
Тот
gemm
который
в
EML
оказался
однопоточным
Соответственно
нам
пришлось
написать
многопоточный
gemm
самостоятельно
Идея
такая:
большая
матрица
дробится
на
подблоки
и
потом
уже
идёт
перемножение
этих
маленьких
матриц
Мы
написали
gemm
с
OpenMP
но
он
не
заработал
вылетали
ошибки
Мы
взяли
ручной
пул
потоков
параллелизация
дала
секунды
на
кадр
Далее
нам
дали
удалённый
доступ
к
более
мощному
серверу
с
на
котором
скорость
увеличилась
до
секунды
на
кадр
На
следующем
видео
показана
работа
демо-стенда
с
распознаванием
лиц
на
компьютере
Эльбрус
-PC
с
процессором
Эльбрус
С:
Выводы
и
дальнейшие
планы
Планы:
Мы
планируем
дальше
разбираться
изучать
возможности
VLIW-процессора
По
сути
мы
пока
что
просто
доверяли
компилятору
в
том
что
если
мы
напишем
хороший
код
то
компилятор
его
хорошо
оптимизирует
потому
что
он
знает
особенности
Эльбруса
В
общем
это
было
интересно
будем
разбираться
дальше
Времени
заняло
это
не
очень
много
–
все
операции
по
портированию
заняли
в
общей
сложности
неделю
В
январе
планируем
выложить
PuzzleLib
в
open
source
об
этом
мы
здесь
ещё
напишем
=)
Спасибо
за
внимание!
Теги:
Хабы:
+
Занимаемся
нейросетями
и
голосовыми
помощниками
Карма
Рейтинг
Станислав
Ашманов
Data
Scientist
Публикации
Лучшие
за
сутки
Похожие
Информация
Сайт
Дата
регистрации
апреля
Дата
основания
июня
Численность
–
человек
Местоположение
Россия
Ваш
аккаунт
Разделы
Информация
Услуги
Настройка
языка
©
–
